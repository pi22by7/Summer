we’ll create a script that scrapes the latest news articles from different newspapers and stores the text, which will be fed into the model afterward to get a prediction of its category.a brief introduction to webpage design and html:if we want to be able to extract news articles (or, in fact, any other kind of text) from a website, the first step is to know how a website works.we will follow an example to understand this:when we insert an url into the web browser (i.e. here it delayed sending requests to a web-server by 2 seconds.time.sleep(2)the sleep() function suspends execution of the current thread for a given number of seconds.step 6: extracting content from htmlnow that you’ve made your http request and gotten some html content, it’s time to parse it so that you can extract the values you’re looking for.a)using regular expressionsusing regular expressions for looking up html content is strongly not recommended at all.however, regular expressions are still useful for finding specific string patterns like prices, email addresses, or phone numbers.run a regular expression on the response text to look for specific string patterns:import re  # put this at the top of the file...print(re.findall(r'\$[0-9,. it is used to fetch urls(uniform resource locator)although, here we are using this module for a different purpose, to call libraries like:time(using which we can call sleep() function to delay or suspends execution for the given number of seconds.sys(it is used here to get exception info like type of error, error object, info about the error.step-2: importing librariesnow we will import all the required libraries:1. beautifulsoupto import it, use the following command onto your idefrom bs4 import beautifulsoupthis library helps us with getting html structure of any page that we want to work with and provides functions to access specific elements and extract relevant info.2.